{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: solid;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\n",
    "  border-radius: 10px;\">\n",
    "\n",
    "# **Python et intelligence artificielle**\n",
    "\n",
    "# *Séance n°7 : Apprentissage supervisé et régression*\n",
    "\n",
    "</div>\n",
    "\n",
    "Dans cette séance, vous allez vous initier à l'intelligence artificielle et, plus spécifiquement, à l'**apprentissage**. Vous allez apprendre à manipuler des données, à les analyser et à appliquer des **modèles prédictifs**. Ces compétences sont essentielles pour traiter des données complexes dans vos domaines d'études.\n",
    "\n",
    "## Objectif\n",
    "\n",
    "- Utiliser les bibliothèques **NumPy** et **Pandas** pour manipuler des données.\n",
    "- Explorer et visualiser les données avec **Matplotlib**.\n",
    "- Découvrir les bases de l'**apprentissage supervisé** avec **Scikit-learn**.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### 1. *NumPy* et *Pandas*\n",
    "\n",
    "Pour manipuler des données en Python, il existe deux bibliothèques essentielles : *NumPy* et *Pandas*. Celles-ci permettent de **stocker, manipuler et transformer** les données avant de les analyser ou de les utiliser dans des modèles d'apprentissage.\n",
    "\n",
    "#### 1.1. NumPy\n",
    "\n",
    "[*NumPy*](https://numpy.org/doc/stable/index.html) est une bibliothèque de calcul scientifique. Elle permet de manipuler des tableaux multidimensionnels (ou vecteurs) et d'appliquer des opérations mathématiques sur ces structures.\n",
    "\n",
    "> **Quand utiliser *NumPy* ?** Vous l'utiliserez chaque fois que vous avez des données numériques (comme des températures, pressions, tensions) sous forme de vecteurs ou de matrices, et que vous voulez faire des opérations comme la moyenne, la somme, ou encore des calculs statistiques.\n",
    "\n",
    "##### Exemple\n",
    "\n",
    "Imaginez que vous ayez une série de mesures. Avec *NumPy*, vous pouvez facilement calculer la **moyenne** de ces mesures, détecter la valeur maximale ou la minimale sans utiliser de boucles trop complexes.\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Exemple d'un tableau NumPy de mesures\n",
    "mesures = np.array([22.5, 23.0, 22.8, 23.1, 22.9, 20.1, 19.8])\n",
    "\n",
    "# Calculs des moyenne et écart type sur le tableau\n",
    "moyenne = np.mean(mesures)\n",
    "ecart_type = np.std(mesures)\n",
    "\n",
    "print(f\"Moyenne des mesures : {moyenne}\")\n",
    "print(f\"Écart-type : {ecart_type}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "#### 1.2. Pandas\n",
    "\n",
    "[*Pandas*](https://pandas.pydata.org/docs/reference/index.html) est une bibliothèque permettant de manipuler des données tabulaires. Elle fournit des structures appelées **DataFrames**, qui ressemblent à des tableaux de données (`DataFrame` est en réalité une classe !). Un *DataFrame* permet une manipulation des données de façon plus flexible que *NumPy* car il peut contenir des colonnes de types différents.\n",
    "\n",
    "> **Quand utiliser *Pandas* ?** Lorsque vous manipulez des données complexes issues par exemple de capteurs et où chaque ligne représente une mesure et chaque colonne représente une caractéristique différente (par exemple, la température, la pression, l'emplacement du capteur, etc.). *Pandas* permet alors de filtrer les données, puis de regrouper les mesures par type de capteur et alors de calculer des moyennes par catégorie.\n",
    "\n",
    "##### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Exemple de DataFrame Pandas pour des capteurs\n",
    "df_capteurs = pd.DataFrame({\n",
    "      'id_capteur': ['C001', 'C002', 'C003', 'C004', 'C005'],\n",
    "      'type': ['Température', 'Pression', 'Humidité', 'Température', 'Pression'],\n",
    "      'valeur': [22.5, 1.02, 45.0, 23.1, 1.01],\n",
    "      'unité': ['°C', 'bar', '%', '°C', 'bar']\n",
    "})\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "print(df_capteurs.head())\n",
    "\n",
    "# Filtrer les capteurs de température dans le DataFrame\n",
    "capteurs_temperature = df_capteurs[df_capteurs['type'] == 'Température']\n",
    "print(capteurs_temperature)\n",
    "\n",
    "# Calculer la moyenne des valeurs par type de capteur\n",
    "moyenne_par_type = df_capteurs.groupby('type')['valeur'].mean()\n",
    "print(moyenne_par_type)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Visualisation des données avec Matplotlib\n",
    "\n",
    "Une fois que vous avez manipulé vos données, vous pouvez utiliser *Matplotlib* afin de comprendre les relations entre variables ou encore pour y distinguer des anomalies.\n",
    "\n",
    "##### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Données de température\n",
    "temps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "temperatures = [22.5, 23.0, 22.8, 23.1, 22.9, 23.2, 21.4, 22.6, 21.0, 21.5]\n",
    "\n",
    "# Tracer l'évolution de la température dans le temps\n",
    "plt.plot(t, temperatures)\n",
    "plt.title(\"Évolution de la température au cours du temps\")\n",
    "plt.xlabel(\"Temps (s)\")\n",
    "plt.ylabel(\"Température (°C)\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "Le graphique généré montre comment la température évolue dans le temps. Vous pourriez l'utiliser pour surveiller le comportement d'un capteur au fil du temps et détecter des anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Apprentissage supervisé avec *Scikit-learn*\n",
    "\n",
    "L'**apprentissage supervisé** est une méthode d'**apprentissage** dans laquelle un modèle est entraîné sur des **données étiquetées** (c'est-à-dire des données pour lesquelles les résultats sont déjà connus). Une fois entraîné, il peut ensuite faire des **prédictions** sur de nouvelles données.\n",
    "\n",
    "#### *Scikit-learn*\n",
    "\n",
    "**Scikit-learn** est une bibliothèque qui permet de mettre au point des algorithmes d'apprentissage en Python. Elle a été initiée par David Cournapeau (Telecom ParisTech) et est actuellement maintenue par Gaël Varoquaux (ENS, Univ. Paris-Sud). Elle permet d'implémenter rapidement et facilement des modèles de régression, de classification, ainsi que d'autres tâches d'analyse de données.\n",
    "\n",
    "> **Quand utiliser *Scikit-learn* ?** Lorsque vous aurez besoin de créer un **modèle prédictif** ou de réaliser une **classification**. Par exemple, en utilisant une **régression linéaire** afin de prédire la valeur d'une variable en fonction d'une autre.\n",
    "\n",
    "#### Mise en oeuvre\n",
    "\n",
    "Quel que soit le modèle d'apprentissage à mettre en oeuvre, il y a quatre étapes à respecter :\n",
    "\n",
    "1. **Préparation des données** : Séparer les données en un **ensemble d'entraînement** (pour que le modèle apprenne) et un **ensemble de test** (afin de vérifier la capacité du modèle à généraliser).\n",
    "2. **Entraînement du modèle** : Entraîner le modèle à partir de l'ensemble d'entraînement.\n",
    "3. **Prédiction** : Une fois le modèle entraîné, on peut utiliser le modèle pour prédire des résultats sur l'ensemble de test.\n",
    "4. **Évaluation** : Évaluer la performance du modèle avec des métriques comme l'**erreur quadratique moyenne** (RMSE pour *root mean squared error*) et le **coefficient de détermination** ($R^2$).\n",
    "\n",
    "**Remarque** :\n",
    "\n",
    "- L'**erreur quadratique moyenne** mesure la différence entre les valeurs réelles et les valeurs prédites. Plus cette valeur tend vers **0**, mieux c'est.\n",
    "- Le **coefficient de détermination** mesure la *précision* du modèle en indiquant dans quelle mesure les prédictions du modèle sont proches des valeurs réelles. Un $R^2$ qui tend vers **1** indique une bonne précision.\n",
    "\n",
    "#### Exemple\n",
    "\n",
    "On rappelle que la **régression linéaire** est une technique qui cherche à établir une relation linéaire entre une **variable dépendante** $y$ et une ou plusieurs **variables indépendantes** $X_{1}, \\cdots, X_{n}$.\n",
    "Dans le cas d'une régression linéaire simple, nous avons une seule variable explicative $X$ et une variable cible $y$. La relation entre ces deux variables peut être exprimée par l'équation d'une droite :\n",
    "$$y = \\theta_1 X + \\theta_0$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $\\theta_1$ correspond à la pente de la droite de régression qui indique de combien la variable cible $y$ change lorsque $X$ augmente d'une unité.\n",
    "- $\\theta_0$  est l'ordonnée à l'origine (*intercept* en anglais), soit la valeur de $y$ lorsque $X = 0$.\n",
    "\n",
    "Par exemple, si l'on souhaite prédire l'humidité ($y$) dans une salle en fonction de la température ($X$), il suffit de mettre en oeuvre un modèle de régression linéaire simple avec des données passées puis de l'estimer à partir de nouvelles valeurs de température.\n",
    "\n",
    "Voici les quatres étapes à réaliser dans le cas d'une régression linéaire simple :\n",
    "\n",
    "##### 1. Préparation des données\n",
    "\n",
    "La première étape consiste à préparer les données en les divisant en **variables explicatives** (*features* en anglais, représentées par `X`) et une **variable cible** (*target*, représentée par `y`). Ensuite, on divise les données en un ensemble d'entraînement et un ensemble de test.\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "# Importation des bibliothèques nécessaires\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Exemple de données\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Variables explicatives (par exemple, température)\n",
    "y = np.array([1.5, 2.0, 2.5, 3.5, 5.0])  # Variable cible (par exemple, humidité)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement (80%) et de test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Affichage des ensembles d'entraînement et de test\n",
    "print(\"Ensemble d'entraînement (X_train) :\", X_train)\n",
    "print(\"Ensemble de test (X_test) :\", X_test)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "- **`train_test_split`** est une fonction qui permet de diviser les données en un ensemble d'entraînement et un ensemble de test.\n",
    "\n",
    "##### 2. Création et entraînement du modèle\n",
    "\n",
    "Ensuite, nous créons un modèle de régression linéaire simple en utilisant *Scikit-learn* qui propose la classe `LinearRegression`, puis nous l'entraînons sur nos données d'entraînement.\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "# Importation du modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Création de l'instance du modèle\n",
    "modele = LinearRegression()\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "modele.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des coefficients du modèle\n",
    "print(f\"Coefficient (pente) : {modele.coef_}\")\n",
    "print(f\"Ordonnée à l'origine (intercept) : {modele.intercept_}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "- **`LinearRegression()`** crée une instance du modèle de régression linéaire.\n",
    "- **`fit(X_train, y_train)`** entraîne le modèle sur les données d'entraînement. Le modèle \"apprend\" à prédire la relation entre `X` et `y`. Nous détaillerons d'ailleurs dans la séance suivante comment le modèle apprend.\n",
    "\n",
    "##### 3. Prédiction\n",
    "\n",
    "Une fois le modèle entraîné, on peut l'utiliser pour faire des **prédictions** sur de nouvelles données (ici, l'ensemble de test).\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "# Utilisation du modèle pour prédire les valeurs sur l'ensemble de test\n",
    "predictions = modele.predict(X_test)\n",
    "\n",
    "# Affichage des prédictions\n",
    "print(\"Valeurs prédites :\", predictions)\n",
    "print(\"Valeurs réelles :\", y_test)\n",
    "```\n",
    "\n",
    "</div>\n",
    "- **`predict(X_test)`** utilise le modèle entraîné pour prédire les valeurs de `y` à partir des valeurs de `X_test`.\n",
    "\n",
    "##### Évaluation du modèle\n",
    "\n",
    "Enfin, il est important de mesurer la **précision** du modèle à l'aide de différents métriques. Ici, nous mesurons l'erreur quadratique moyenne et le coefficient de détermination.\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "# Importation des métriques d'évaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calcul du MSE (erreur quadratique moyenne)\n",
    "mse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "# Calcul du coefficient de détermination (R²)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "# Affichage des métriques d'évaluation\n",
    "print(f\"MSE : {mse}\")\n",
    "print(f\"R^2 : {r2}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "- **`mean_squared_error(y_test, predictions)`** calcule l'erreur quadratique moyenne.\n",
    "- **`r2_score(y_test, predictions)`** mesure le coefficient de détermination.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercices\n",
    "\n",
    "### Exercice 1 : Manipulation de données avec *NumPy* et *Pandas*\n",
    "\n",
    "**Objectif :** Apprendre à manipuler des données numériques et tabulaires en utilisant *NumPy* et *Pandas*.\n",
    "\n",
    "#### Travail demandé\n",
    "\n",
    "1. **Importation des bibliothèques :**\n",
    "\n",
    "   - Importez les bibliothèques `numpy` et `pandas` sous les alias respectif `np` et `pd`.\n",
    "\n",
    "2. **Création d'un tableau *NumPy* :**\n",
    "\n",
    "   - Créez un tableau *NumPy* nommé `temperatures` contenant les valeurs suivantes : `22.5`, `23.0`, `22.8`, `23.1`, `22.9`, `22.8`, `22.7`.\n",
    "\n",
    "3. **Calculs avec *NumPy* :**\n",
    "\n",
    "   - Calculez et affichez la moyenne, l'écart-type, la valeur maximale et minimale des températures.\n",
    "\n",
    "4. **Création d'un DataFrame *Pandas* :**\n",
    "\n",
    "   - Créez un DataFrame nommé `df_capteurs` avec les colonnes suivantes :\n",
    "     - `id_capteur` : `['C001', 'C002', 'C003', 'C004', 'C005']`\n",
    "     - `type` : `['Température', 'Pression', 'Humidité', 'Température', 'Pression']`\n",
    "     - `valeur` : `[22.5, 1.02, 45.0, 23.1, 1.01]`\n",
    "     - `unité` : `['°C', 'bar', '%', '°C', 'bar']`\n",
    "\n",
    "5. **Manipulation du DataFrame :**\n",
    "\n",
    "   - Affichez les premières lignes du DataFrame.\n",
    "   - Sélectionnez uniquement les capteurs de température et affichez leurs informations.\n",
    "   - Calculez la moyenne des valeurs pour chaque type de capteur.\n",
    "\n",
    "#### Remarques\n",
    "\n",
    "- Utilisez les fonctions `np.mean()`, `np.std()`, `np.max()`, et `np.min()` pour les calculs avec *NumPy*.\n",
    "- Avec *Pandas*, utilisez `df.head()`, `df[df['type'] == 'Température']`, et `df.groupby()` pour les manipulations.\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 2 : Chargement et analyse d'un jeu de données météorologiques\n",
    "\n",
    "Le fichier \"`donnees_capteurs.csv`\" disponible dans le dossier `ressources` contient les colonnes suivantes :\n",
    "\n",
    "- heure de la mesure ;\n",
    "- température en °C ;\n",
    "- pression en hPa ;\n",
    "- pourcentage d'humidité.\n",
    "\n",
    "#### Travail demandé\n",
    "\n",
    "1. Chargez le fichier dans un *DataFrame* *Pandas* nommé `df_donnees`.\n",
    "2. **Exploration des données** :\n",
    "\n",
    "   - Affichez les informations générales du *DataFrame* (`df.info()`).\n",
    "   - Affichez les statistiques descriptives des données numériques (`df.describe()`).\n",
    "   - Vérifiez s'il y a des valeurs manquantes dans le *DataFrame* et gérez-les de manière appropriée (en les remplaçant par exemple par la moyenne).\n",
    "\n",
    "3. **Nettoyage des données** :\n",
    "   - Convertissez la colonne `heure` qui est une chaîne de caractères en un format conventionnel afin de manipuler plus facilement la dimension temporelle si cela est nécessaire :\n",
    "\n",
    "     ```python\n",
    "     df_donnees['heure'] = pd.to_datetime(df_donnees['heure'], format='%H:%M:%S')\n",
    "     ```\n",
    "\n",
    "   - Si vous trouvez des valeurs manquantes dans le *DataFrame*, remplacez-les par la moyenne de la colonne correspondante.\n",
    "4. **Visualisation des données** :\n",
    "\n",
    "   - Tracez l'évolution de la température au cours du temps en utilisant *Matplotlib*.\n",
    "   - Créez un histogramme de la distribution des pressions mesurées.\n",
    "   - Réalisez un nuage de points (*scatter plot*) entre la température et l'humidité afin d'observer les corrélations éventuelles.\n",
    "5. **Analyse statistique** :\n",
    "\n",
    "   - Utilisez `df.corr()` pour calculer les coefficients de corrélation entre les différentes variables (température, pression, humidité) et interprétez les résultats.\n",
    "   - Quels sont les couples de variables les plus corrélés ? Pouvez-vous expliquer pourquoi ?\n",
    "\n",
    "#### Remarques\n",
    "\n",
    "- Utilisez `pd.read_csv()` pour charger les données depuis un fichier CSV.\n",
    "- Les fonctions `df.isnull().sum()` et `df.dropna()` peuvent vous être utiles pour le nettoyage.\n",
    "- Pour les visualisations, reportez-vous aux exercices de la [séance n°2](https://github.com/alainlebret/python-et-ia-1).\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 3 : Introduction à l'apprentissage automatique avec *Scikit-learn*\n",
    "\n",
    "Maintenant que vous avez exploré et nettoyé vos données, vous allez utiliser des modèles d'apprentissage supervisé pour tenter de prédire une variable en fonction des autres. Vous commencerez par prédire l'humidité en fonction de la température et de la pression.\n",
    "\n",
    "#### Travail demandé\n",
    "\n",
    "1. Sélectionnez les colonnes `temperature` et `pression` comme variables explicatives ($X$) et la colonne humidite comme variable cible (`y`).\n",
    "2. Séparez les données en un ensemble d'entraînement et un ensemble de test (par exemple, 80% pour l'entraînement, 20% pour le test).\n",
    "3. Utilisez un modèle de régression linéaire afin de modéliser la relation entre l'humidité, la température et la pression et entraînez-le.\n",
    "4. Affichez les coefficients du modèle (pente pour chaque variable explicative).\n",
    "5. Évaluez le modèle :\n",
    "   - Prédisez les valeurs d'humidité pour l'ensemble de test.\n",
    "   - Évaluez la performance du modèle en calculant l'erreur quadratique moyenne et le coefficient de détermination ($R^2$).\n",
    "6. Tracez un graphique comparant les valeurs prédites et les valeurs réelles d'humidité.\n",
    "7. Que pouvez-vous conclure de la qualité des prédictions du modèle ?\n",
    "8. Quels facteurs pourraient influencer la performance du modèle (qualité des données, manque d’informations, etc.) ?\n",
    "\n",
    "#### Remarque\n",
    "\n",
    "Pensez à importez les modules nécessaires :\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "```\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 4 : Standardisation du jeu de données météorologiques\n",
    "\n",
    "Le fichier \"`donnees_capteurs.csv`\" que vous avez utilisé précédemment contient des variables dont les unités et les échelles de valeurs sont suffisament différentes pour impacter leur analyse (ex. : les pressions sont autour de 1000 hPa et les températures autour de 20 °C). C'est la raison pour laquelle, il est fréquemment nécessaire de **standardiser** les données avant de les analyser. En effet, sans cette standisation les modèles peuvent donner une importance disproportionnée à certaines variables.\n",
    "\n",
    "#### Standardisation\n",
    "\n",
    "La standardisation consiste à transformer les données pour qu'elles aient une moyenne de 0 et un écart-type de 1. Cette technique est utilisée lorsque vous voulez centrer les données autour de leur moyenne et réduire leur dispersion pour qu'elles suivent une distribution gaussienne. Elle réalise la transformation suivante :\n",
    "\n",
    "$$\n",
    "X_{\\text{standardisée}} = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $X$ est la valeur de la variable à standardiser ;\n",
    "- $\\mu$ est la moyenne des données ;\n",
    "- $\\sigma$ est l'écart-type.\n",
    "\n",
    "La standardisation est donc particulièrement utile lorsque les variables ont des unités différentes (par exemple, la pression en hPa et la température en °C), mais aussi si l'algorithme d'apprentissage utilise des distances comme c'est le cas pour la régression linéaire.\n",
    "\n",
    "Dans cet exercice, nous allons vérifier si la standardisation améliore les résultats de notre modèle\n",
    "de régression linéaire.\n",
    "\n",
    "#### Travail demandé\n",
    "\n",
    "1. Appliquez une standardisation sur les variables explicatives de votre jeu de données à l'aide d'une instance de la classe `StandardScaler` et en appliquant sa méthode `fit_transform()` :\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   \n",
    "   scaler = StandardScaler()\n",
    "   X_scaled = scaler.fit_transform(X)\n",
    "   ```\n",
    "\n",
    "2. Tracez un graphique comparant la distribution des variables avant et après normalisation pour comprendre l’effet de la transformation.\n",
    "3. Séparez les données standardisées en un ensemble d'entraînement et un ensemble de test.\n",
    "4. Entraînez un modèle de régression linéaire sur l'ensemble d'entraînement standardisé.\n",
    "5. Comparez les performances avec celles obtenues sur le jeu de données non standardisé.\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercice 5 : Régression linéaire et polynomiale sur un nouveau jeu de données\n",
    "\n",
    "Utiliser un nouveau jeu de données avec une relation plus complexe (non linéaire), appliquer la standardisation, puis comparer les performances entre une régression linéaire et une régression polynomiale.\n",
    "\n",
    "Le jeu de données présent dans le fichier \"`donnees_capteurs3.csv`\" contient les mêmes\n",
    "colonnes que celles du fichier précédent, mais les données ont une relation plus complexes entre elles. Dans cet exercice, nous allons comparer un modèle de régression linéaire avec un modèle de régression polynomial.\n",
    "\n",
    "#### Travail demandé\n",
    "\n",
    "1. Régression linéaire :\n",
    "   - Séparez les données en ensemble d'entraînement (80 %) et de test (20 %).\n",
    "   - Entraînez un modèle de régression linéaire avec les données standardisées.\n",
    "   - Évaluez la performance du modèle à l'aide du MSE et du coefficient de détermination ($R^2$).\n",
    "2. Régression polynomiale :\n",
    "   - Utilisez la classe `PolynomialFeatures` de *Scikit-learn* pour ajouter des termes quadratiques dans les données en l'instanciant avec un degré 2 (`PolynomialFeatures(degree=2)`).\n",
    "   - Entraînez un modèle de régression polynomiale à l'aide de la classe `LinearRegression`.\n",
    "   - Comparez les performances avec celles de la régression linéaire.\n",
    "\n",
    "#### Quelques mots sur la classe `PolynomialFeatures`\n",
    "\n",
    "Lorsque vous utilisez `PolynomialFeatures(degree=2)`, cela a pour effet de créer de nouvelles variables à partir des variables d’entrée $X_1$ (température) et $X_2$ (pression). Notamment les variables :\n",
    "\n",
    "- $X_1^2$ (température au carré)\n",
    "- $X_2^2$ (pression au carré)\n",
    "- $X_1 \\cdot X_2$ (terme d'interaction entre température et pression)\n",
    "\n",
    "Donc, si votre modèle linéaire était initialement de la forme :\n",
    "\n",
    "$$\n",
    "y = \\theta_0 + \\theta_1 X_1 + \\theta_2 X_2\n",
    "$$\n",
    "\n",
    "Il devient :\n",
    "$$\n",
    "y = \\theta_0 + \\theta_1 X_1 + \\theta_2 X_2 + \\theta_3 X_1^2 + \\theta_4 X_2^2 + \\theta_5 X_1 X_2\n",
    "$$\n",
    "\n",
    "Cela permet à un modèle linéaire d'ajuster des courbes quadratiques ou d'autres formes complexes, et donc de modéliser des relations non linéaires entre les variables.\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Au cours de cette séance, vous avez :\n",
    "\n",
    "- Découvert comment utiliser *NumPy* et *Pandas* afin de manipuler et d'analyser des données numériques et tabulaires.\n",
    "- Appris à charger des jeux de données réels, à les nettoyer, les standardiser et à les explorer.\n",
    "- Utilisé *Matplotlib* pour visualiser les données et extraire des informations pertinentes.\n",
    "- Fait vos premiers pas en **apprentissage automatique** en appliquant une régression linéaire afin de modéliser la relation entre la température et la pression, et l'humidité.\n",
    "\n",
    "---\n",
    "\n",
    "## Références\n",
    "\n",
    "Voici trois ouvrages que vous devriez lire si vous souhaitez vous tourner vers les domaines qui relèvent de l'IA et plus particulièrement de l'apprentissage automatique.\n",
    "\n",
    "- Aurélien Géron. *Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow* (3e édition). O'Reilly Media, 2022.\n",
    "- Christopher M. Bishop. *Pattern Recognition and Machine Learning* (2e édition). Springer-Verlag, 2011.\n",
    "- Andriy Burkov. *The Hundred-Page Machine Learning Book*. Auto-édition, 2019.\n",
    "\n",
    "Pour l'apprentissage profond, je vous conseille le livre suivant :\n",
    "\n",
    "- François Chollet. *Deep Learning With Python* (2e édition). Manning Publications, 2022.\n",
    "\n",
    "## Bases de données pour l'apprentissage\n",
    "\n",
    "- [Kaggle](https://www.kaggle.com)\n",
    "- [Sigma.ai](https://sigma.ai/open-datasets/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
