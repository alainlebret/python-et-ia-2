{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: solid;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\n",
    "  border-radius: 10px;\">\n",
    "  \n",
    "# **Python et intelligence artificielle**\n",
    "\n",
    "# *Séance n°9 : Apprentissage supervisé et classification*\n",
    "\n",
    "</div>\n",
    "\n",
    "Dans cette séance, vous allez approfondir vos connaissances en **apprentissage supervisé** avec *Scikit-learn* en explorant le **concept de classification** appliqué à la détection d'anomalies. Vous apprendrez à évaluer vos modèles de manière robuste en utilisant d'autres **métriques d'évaluation** ainsi que la technique de **validation croisée**.\n",
    "\n",
    "Vous apprendrez entre autres à :\n",
    "\n",
    "- Analyser et visualiser un jeu de données afin d'en extraire des tendances.\n",
    "- Entraîner un modèle de **classification binaire** et ajuster ses hyperparamètres.\n",
    "- Appliquer plusieurs **métriques d'évaluation** pour déterminer la précision du modèle.\n",
    "- Comparer différents modèles de classification (**régression logistique**, **k-NN** et **machine à vecteurs de support**).\n",
    "- Utiliser la **validation croisée** pour évaluer la robustesse d'un modèle.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "La **classification** est une méthode d'apprentissage où l'objectif est\n",
    "de prédire une **classe** (catégorie) à partir des données d'entrée. Dans cette séance,\n",
    "nous étudierons trois algorithmes pour la classification binaire, afin de déterminer\n",
    "si un objet est une mine sous-marine ou une roche. Ce type de classification est\n",
    "largement utilisée dans l'industrie afin d'anticiper les défaillances d'équipements,\n",
    "mais aussi dans le domaine de la santé pour la détection de maladies ou encore dans\n",
    "le domaine de la finance pour détecter les fraudes.\n",
    "\n",
    "Les trois modèles que nous allons mettre en oeuvre sont :\n",
    "\n",
    "- la **régression logistique**, qui permet de prédire une probabilité d'appartenance\n",
    "  à une classe et est adaptée aux classes linéairement séparables ;\n",
    "- le **k-plus proches voisins** (k-NN), qui classe une observation en fonction des\n",
    "  $k$ voisins les plus proches dans l'espace des caractéristiques et qui convient aux\n",
    "  relations plus complexes ;\n",
    "- la **machine à vecteurs de support** (SVM) particulièrement efficace pour les\n",
    "  problèmes de classification non linéaire.\n",
    "\n",
    "### Description des données\n",
    "\n",
    "Le jeu de données \"`sonar.csv`\" du sous-dossier \"ressources\" contient des mesures de\n",
    "signaux sonar réfléchis par des objets sous-marins cylindriques et classe les signaux\n",
    "en deux catégories : mines et roches.\n",
    "La structure et la densité de l'objet (mine ou roche) influencent la façon dont les\n",
    "ondes émise par le sonar sont réfléchies dans chaque bande de fréquence. Par exemple,\n",
    "une mine, souvent en métal, pourrait produire des réflexions différentes par rapport\n",
    "à une roche de même taille.\n",
    "\n",
    "#### Structure et caractéristiques des données\n",
    "\n",
    "Le fichier est décomposé en 208 lignes de 61 colonnes.\n",
    "\n",
    "- Chacune des 60 premières colonnes représente l'intensité de réflexion du signal\n",
    "  sonar dans un intervalle de fréquence donné. Ces valeurs correspondent aux amplitudes\n",
    "  mesurées dans différentes bandes de fréquence, de la plus basse (caractéristique 1) à la\n",
    "  plus élevée (caractéristique 60). Les amplitudes sont normalisées dans une plage entre\n",
    "  0.0 et 1.0. Une valeur proche de 1 indique une forte intensité de réflexion dans cette\n",
    "  bande de fréquence, tandis qu'une valeur proche de 0 indique une faible intensité.\n",
    "- La dernière colonne représente la classe cible qui étiquette chaque échantillon comme\n",
    "  \"R\" pour roche ou \"M\" pour mine.\n",
    "\n",
    "Les 60 caractéristiques sont souvent corrélées entre elles, et une analyse préliminaire\n",
    "(par exemple avec une carte de corrélation) peut vous permettre d'identifier les relations\n",
    "entre fréquences et d'évaluer si certaines bandes de fréquences sont plus discriminantes\n",
    "pour distinguer les deux classes.\n",
    "\n",
    "### Régression logistique\n",
    "\n",
    "La **régression logistique** est un modèle probabiliste conçu pour la **classification binaire**. Contrairement à la régression linéaire, elle utilise une fonction logistique pour transformer la sortie en une probabilité d'appartenance à une classe. Elle est bien adaptée pour des données linéairement séparables.\n",
    "\n",
    "La probabilité qu'une observation appartienne à la classe positive est donnée par la **fonction sigmoïde** :\n",
    "\n",
    "$$\n",
    "P(y=1|X) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "où $z$ est une combinaison linéaire des variables explicatives :\n",
    "\n",
    "$$\n",
    "z = a_0 + a_1 X_1 + a_2 X_2 + \\dots + a_n X_n\n",
    "$$\n",
    "et $\\sigma(z)$ renvoie une valeur comprise entre 0 et 1 qui représente la probabilité que $y$ soit\n",
    "égal à 1 (appartenance à la classe positive).\n",
    "\n",
    "#### Décision et seuil\n",
    "\n",
    "La régression logistique utilise un **seuil** généralement fixé à 0,5 pour la\n",
    "prise de décision :\n",
    "\n",
    "- $\\text{Si } P(y=1|X) > \\text{seuil} \\Rightarrow y = 1 \\quad \\text{(classe positive)}$\n",
    "- $\\text{Si } P(y=1|X) \\leq \\text{seuil} \\Rightarrow y = 0 \\quad \\text{(classe négative)}$\n",
    "\n",
    "#### Fonction de coût et optimisation\n",
    "\n",
    "La **log-vraisemblance** représente la probabilité d'observer les données étant\n",
    "donné les paramètres du modèle. La **log-vraisemblance négative** est utilisée\n",
    "comme **fonction de coût**, et elle est minimisée afin d'obtenir le meilleur\n",
    "ajustement possible :\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left( y^{(i)} \\log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_{\\theta}(x^{(i)})) \\right)\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $m$ est le nombre d'exemples dans le jeu de données d'entraînement ;\n",
    "- $x^{(i)}$ est le $i$-ème exemple d'entraînement ;\n",
    "- $y^{(i)}$ est l'étiquette de l'exemple $i$, soit 0 ou 1 ;\n",
    "- $h_{\\theta}(x^{(i)})$ est la probabilité prédite pour l'exemple $i$ donnée par la fonction sigmoïde.\n",
    "\n",
    "L'objectif est de maximiser la vraisemblance (ou de minimiser sa version négative).\n",
    "\n",
    "La classe `LogisticRegression` de *Scikit-learn* utilise des méthodes d'optimisation\n",
    "comme la **descente de gradient** pour trouver les paramètres optimaux.\n",
    "\n",
    "#### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Modèle de régression logistique\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)     # Entraînement\n",
    "y_pred = log_reg.predict(X_test)  # Prédiction\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "### k-plus proche voisins\n",
    "\n",
    "L'algorithme des **k-plus proches voisins** (ou k-NN) est un modèle de classification non\n",
    "paramétrique :\n",
    "\n",
    "1. Pour classer une observation, il identifie ses $k$ plus proches voisins en termes de distance.\n",
    "2. La classe majoritaire parmi les $k$ voisins est assignée à l'observation.\n",
    "\n",
    "La **distance euclidienne** est souvent utilisée pour mesurer la proximité des voisins.\n",
    "L'algorithme k-NN est simple et fonctionne bien sur des petits jeux de données ou pour des\n",
    "relations locales.\n",
    "\n",
    "*Scikit-learn* fournit l'implémentation d'un k-NN avec la classe `KNeighborsClassifier`.\n",
    "\n",
    "#### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instanciation du modèle k-NN avec k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Entraînement du modèle\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "Remarque : k-NN permet aussi la régression.\n",
    "\n",
    "### Machine à vecteurs de support\n",
    "\n",
    "Une **machine à vecteurs de support** (SVM) est un modèle de classification (linéaire ou non linéaire) qui cherche à séparer des classes en maximisant la marge entre elles. La marge est définie comme la distance entre la frontière de décision et les points les plus proches de chaque classe, appelés *vecteurs de support*.\n",
    "\n",
    "- Si les données sont linéairement séparables, la SVM trouve l'hyperplan (une ligne en 2D, un plan en 3D, etc.) qui maximise la marge.\n",
    "- Pour des données non linéairement séparables, la SVM utilise des **noyaux** pour transformer les données dans un espace de dimension supérieure, dans lequel elles deviennent linéairement séparables. Par exemple :\n",
    "  - Noyau linéaire : pour une séparation linéaire.\n",
    "  - Noyaux polynomial ou radial pour des séparations non linéaires.\n",
    "\n",
    "#### Fonction de coût et régularisation\n",
    "\n",
    "La SVM cherche à trouver l'hyperplan qui sépare au mieux les classes en maximisant la marge entre elles tout en minimisant les erreurs de classification. Ceci est formulé comme un problème d'optimisation qui minimise une fonction de coût associée.\n",
    "\n",
    "Pour les SVM à **marge souple** (*soft margin*), le problème d'optimisation est défini par :\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{w}, b} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^{n} \\xi_i\n",
    "$$\n",
    "\n",
    "sous les contraintes :\n",
    "\n",
    "$$\n",
    "y_i (\\mathbf{w}^\\top \\mathbf{x_i} + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0, \\quad \\forall i = 1, \\dots, n\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $\\mathbf{w}$ est le vecteur des poids (coefficients de l'hyperplan),\n",
    "- $b$ est le biais,\n",
    "- $y_i$ est la classe de l'exemple $i$ ($y_i = +1$ ou $y_i = -1$),\n",
    "- $\\mathbf{x_i}$ est le vecteur des caractéristiques de l'exemple $i$,\n",
    "- $\\xi_i$ sont les variables de relaxation (*slack variables*) qui permettent de pénaliser les erreurs de classification,\n",
    "- $C$ est le paramètre de régularisation qui contrôle le compromis entre maximiser la marge et minimiser les erreurs de classification.\n",
    "\n",
    "Le terme $\\frac{1}{2} \\|\\mathbf{w}\\|^2$ vise à maximiser la marge (en minimisant la norme de $\\mathbf{w}$), tandis que le terme $C \\sum_{i=1}^{n} \\xi_i$ pénalise les erreurs de classification (les points mal classés ou à l'intérieur de la marge).\n",
    "\n",
    "Un $C$ élevé donne une pénalité plus forte pour les erreurs de classification, ce qui conduit à une marge plus petite pour minimiser les erreurs. Un $C$ faible permet une marge plus large au prix de plus d'erreurs, favorisant une meilleure généralisation.\n",
    "\n",
    "En Python, *Scikit-Learn* propose une implémentation des SVM avec la classe `SVC`.\n",
    "\n",
    "#### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instanciation du modèle SVM avec un noyau linéaire\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Entraînement du modèle\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "- Le paramètre `kernel` contrôle le type de noyau utilisé. Ici, nous avons choisi le noyau linéaire (`kernel='linear'`), mais d'autres options, comme `poly` pour un noyau polynomial ou `rbf` pour un noyau radial, sont également disponibles pour des séparations non linéaires.\n",
    "\n",
    "Remarque : SVM permet aussi la régression.\n",
    "\n",
    "### Comparaison entre régression logistique et k-NN\n",
    "\n",
    "|    **Modèle**         |                  **Avantages**                      |         **Inconvénients**            |\n",
    "|:---------------------:|-----------------------------------------------------|--------------------------------------|\n",
    "| Régression logistique | Facile à interpréter, adaptée aux données linéaires | Limitée aux séparations linéaires    |\n",
    "|      k-NN             | Simple, efficace pour relations locales             | Sensible aux données bruitées        |\n",
    "|       SVM             | Performant pour les séparations non linéaires       | Complexe et coûteux pour grands jeux |\n",
    "\n",
    "---\n",
    "\n",
    "## Évaluation des modèles\n",
    "\n",
    "### Métriques pour la régression\n",
    "\n",
    "Pour la régression, nous utilisons l'erreur quadratique moyenne MSE ou encore sa\n",
    "racine carrée (RMSE) ainsi que le coefficient de détermination $R^2$.\n",
    "\n",
    "### Métriques pour la classification\n",
    "\n",
    "#### 1. **Matrice de confusion**\n",
    "\n",
    "La **matrice de confusion** est un tableau qui permet d'évaluer la performance\n",
    "d'un modèle de classification en comparant les prédictions aux résultats réels.\n",
    "Elle contient quatre types de prédictions :\n",
    "\n",
    "- **Vrais positifs (VP)** : instances positives correctement classées.\n",
    "- **Faux positifs (FP)** : instances négatives incorrectement classées comme positives.\n",
    "- **Faux négatifs (FN)** : instances positives incorrectement classées comme négatives.\n",
    "- **Vrai négatifs (VN)** : instances négatives correctement classées.\n",
    "\n",
    "Exemple de matrice de confusion pour une classification binaire :\n",
    "\n",
    "|                              | **Prédiction : positif** | **Prédiction : négatif** |\n",
    "|------------------------------|:------------------------:|:------------------------:|\n",
    "| **Classe réelle : positif**  |            VP            |            FN            |\n",
    "| **Classe réelle : négatif**  |            FP            |            VN            |\n",
    "\n",
    "Avec *scikit-learn*, on utilisera la fonction `confusion_matrix()` :\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "La matrice de confusion nous permet de définir plusieurs métriques pour évaluer la performance d'un modèle de classification : la précision, le rappel et la F-mesure.\n",
    "\n",
    "#### 2. **Précision**\n",
    "\n",
    "La précision correspond à proportion des prédictions positives correctes parmi les prédictions positives. Elle est définie par :\n",
    "\n",
    "$$\n",
    "\\text{Précision} = \\frac{VP}{VP + FP}\n",
    "$$\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "  \n",
    "```python\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Précision : {precision}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "#### **Rappel**\n",
    "\n",
    "Le rappel renseigne sur la proportion des vrais positifs parmi toutes les instances réellement positives. Il est défini par :\n",
    "\n",
    "$$\n",
    "\\text{Rappel} = \\frac{VP}{VP + FN}\n",
    "$$\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "rappel = recall_score(y_test, y_pred)\n",
    "print(f'Rappel : {rappel}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "#### 3. **F-mesure**\n",
    "\n",
    "La F-mesure (ou score F1) correspond à la moyenne harmonique de la précision et\n",
    "du rappel. C'est une mesure globale de la performance qui est utile lorsque les\n",
    "classes sont déséquilibrées. La F-mesure est définie par :\n",
    "\n",
    "$$\n",
    "F1 = 2 \\times \\frac{\\text{Précision} \\times \\text{Rappel}}{\\text{Précision} + \\text{Rappel}}\n",
    "$$\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "  \n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F-mesure : {f1}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "Remarque : Pour un ensemble de $n$ valeurs $x_1, x_2, \\dots, x_n$, la moyenne harmonique est donnée par :\n",
    "\n",
    "$$\n",
    "H = \\frac{n}{\\sum_{i=1}^n \\frac{1}{x_i}}\n",
    "$$\n",
    "\n",
    "#### 4. Rapport de classification\n",
    "\n",
    "Il est possible de récupérer un rapport complet de ces différents métriques\n",
    "en appelant la fonction `classification_report()` :\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "  \n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "#### 5. Exactitude\n",
    "\n",
    "On peut aussi mesurer la performance d'un modèle de classification en calculant\n",
    "son **exactitude**. L'exactitude (*accuracy*) représente la proportion\n",
    "d'observations correctement classées parmi l'ensemble des observations. Elle est\n",
    "définie par :\n",
    "\n",
    "$$\n",
    "\\text{Exactitude} = \\frac{VP + VN}{VP + VN + FP + FN}\n",
    "$$\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "  \n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitude = accuracy_score(y_test, y_pred)\n",
    "print(f'Exactitude : {exactitude}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "#### 6. Courbe ROC et AUC\n",
    "\n",
    "La courbe **ROC** (*receiver operating characteristic*) est un graphique qui\n",
    "illustre la performance d'un modèle de classification binaire en fonction de\n",
    "son taux de vrais positifs (le rappel) et de son taux de faux positifs (FPR).\n",
    "Ce **FPR** (*false positive rate*) est la proportion de faux positifs parmi\n",
    "les négatifs. La figure ci-dessous présente les courbes ROC de différents \n",
    "types de modèles.\n",
    "\n",
    "![Modèles de classificateurs et courbes ROC](figures/courbes_ROC.svg)\n",
    "\n",
    "La courbe ROC est tracée en faisant varier le seuil de décision du modèle. Elle permet\n",
    "d'observer comment la capacité de classification change en fonction du seuil et de\n",
    "choisir le seuil le mieux adapté.\n",
    "\n",
    "L'aire sous la courbe ROC, ou **AUC** (*area under curve*), quantifie la qualité\n",
    "du modèle. Un AUC de 1 signifie que la classification est parfaite, tandis qu'un\n",
    "AUC de 0,5 représente une classification aléatoire.\n",
    "\n",
    "##### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "  \n",
    "```python\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcul de la probabilité de la classe positive\n",
    "y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcul de la courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Affichage de la courbe ROC\n",
    "plt.plot(fpr, tpr, label='Courbe ROC')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Aléatoire')\n",
    "plt.xlabel('Taux de faux positifs (FPR)')\n",
    "plt.ylabel('Rappel')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calcul de l'AUC\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"Aire sous la courbe ROC (AUC) : {auc}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "### Validation croisée\n",
    "\n",
    "La **validation croisée** consiste à diviser les données en plusieurs sous-ensembles\n",
    "(appelés \"folds\"). Le modèle est entraîné sur plusieurs combinaisons de ces\n",
    "sous-ensembles et testé sur les sous-ensembles restants. Cela permet d'améliorer la\n",
    "**robustesse** et de réduire les risques de **sur-apprentissage** (*overfitting*).\n",
    "\n",
    "Dans une validation croisée à $k$ sous-ensembles, chaque sous-ensemble sert de jeu de\n",
    "test une fois, tandis que les $k-1$ sous-ensembles restants forment le jeu d'entraînement.\n",
    "La validation croisée est mise en oeuvre avec la fonction `cross_val_score()`.\n",
    "\n",
    "#### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Validation croisée avec 5 sous-ensembles pour un modèle de régression logistique\n",
    "scores = cross_val_score(log_reg, X, y, cv=5)\n",
    "print(\"Scores de validation croisée (5 sous-ensembles) :\", scores)\n",
    "print(\"Précision moyenne :\", scores.mean())\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "### Comparaison avec les k-plus proches voisins (k-NN)\n",
    "\n",
    "L'algorithme des **k plus proches voisins (k-NN)** est un algorithme de classification\n",
    "où la classe d'une observation est déterminée par les $k$ observations (ou voisins) les\n",
    "plus proches dans le jeu de données.\n",
    "Cet algorithme est souvent utilisé pour sa simplicité et permet une comparaison\n",
    "intéressante avec la régression logistique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercices\n",
    "\n",
    "### Exercice 1 : Analyse et visualisation des données\n",
    "\n",
    "1. Importez les bibliothèques nécessaires\n",
    "\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   import numpy as np\n",
    "   import matplotlib.pyplot as plt\n",
    "   import seaborn as sns\n",
    "   ```\n",
    "\n",
    "2. Chargez les données du fichier \"`sonar.csv`\".\n",
    "3. Examinez les premières lignes du jeu de données et les statistiques descriptives pour identifier la distribution des valeurs dans chaque colonne.\n",
    "4. Visualisez les valeurs des 60 caractéristiques pour les classes \"R\" (roche) et \"M\" (mine) à l'aide de cartes thermiques (*heatmaps*) et de nuages de points. Recherchez des motifs ou des différences entre les classes.\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 2 : Entraînement d'un modèle de régression logistique\n",
    "\n",
    "1. Divisez les données en un ensemble d'entraînement et un ensemble de test en utilisant la\n",
    "   fonction `train_test_split()` de *Scikit-learn* (70% - 30%). Vous penserez à encoder\n",
    "   \"R\" (roche) en 0 et \"M\" (mine) en 1 à l'aide de la méthode `map()` :\n",
    "\n",
    "   ```python\n",
    "   df['class'] = df['class'].map({'R': 0, 'M': 1})\n",
    "   ```\n",
    "\n",
    "2. Instanciez la classe `LogisticRegression` de manière à créer un modèle de régression\n",
    "   logistique. Entraînez ce modèle à l'aide de sa méthode `fit()`), puis faites des prédictions\n",
    "   sur l'ensemble de test à l'aide de sa méthode `predict()`.\n",
    "3. Affichez la matrice de confusion et le rapport complet de classification pour ce modèle.\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercice 3 : Comparaison avec les modèles k-NN et SVM\n",
    "\n",
    "1. Entraînez un modèle k-NN avec les mêmes données ($k = 5$) et un modèle SVM\n",
    "   avec un noyau radial de base (`kernel='rbf'`). Comparez leurs performances\n",
    "   avec celles de la régression logistique.\n",
    "2. La précision et la F-mesure sont-elles plus élevées avec le k-NN, la SVM ou\n",
    "   avec la régression logistique ? Justifiez.\n",
    "3. Utilisez la fonction `accuracy_score()` afin d'obtenir l'exactitude des trois\n",
    "   modèles. Que constatez-vous ?\n",
    "4. Utilisez la fonction `predict_proba()` pour obtenir la probabilité\n",
    "   d'appartenance de chaque observation à la classe positive pour les trois\n",
    "   modèles.\n",
    "5. Utilisez ensuite la fonction `roc_curve()` de *Scikit-learn* pour calculer\n",
    "   les valeurs nécessaires aux trois courbes ROC.\n",
    "6. Tracez les courbes ROC des trois modèles sur le même graphique et interprétez\n",
    "   leurs formes.\n",
    "7. Utilisez la fonction `roc_auc_score()` pour calculer l'aire sous la courbe\n",
    "   ROC (AUC) pour les trois modèles. Quelle est l'importance d'un AUC élevé\n",
    "   pour la détection ?\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 4 : Validation croisée et optimisation d'hyperparamètres\n",
    "\n",
    "1. Utilisez la validation croisée pour tester la robustesse des trois modèles.\n",
    "2. Comparez la moyenne et l'écart-type des scores pour la régression logistique,\n",
    "   le modèle k-NN et la SVM.\n",
    "3. Testez plusieurs valeurs de $k$ pour déterminer celle qui donne les meilleurs\n",
    "   résultats pour le modèle k-NN. Pour la SVM, testez différents noyaux (`'linear'`,\n",
    "   `'poly'`, `'rbf'`) et valeurs du paramètre $C$ pour déterminer la combinaison\n",
    "   optimale. Pourquoi est-il important d'optimiser ces hyperparamètres ?\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Dans cette séance, vous avez :\n",
    "\n",
    "- mis en oeuvre une classification binaire dans le cadre de la détection ;\n",
    "- entraîné trois modèles de classification binaire afin de distinguer les états : une\n",
    "  régression logistique, un k-NN et une SVM ;\n",
    "- utilisé des métriques d'évaluation et la validation croisée afin d'évaluer la\n",
    "  robustesse et la précision des trois modèles.\n",
    "- optimisé les hyperparamètres pour améliorer les performances de vos modèles.\n",
    "\n",
    "---\n",
    "\n",
    "## Références\n",
    "\n",
    "**[1]** T. Sejnowski and R. Gorman. \"Connectionist Bench (Sonar, Mines vs. Rocks),\" UCI Machine Learning Repository, 1988. Jeu de données accessible à l'adresse : [https://doi.org/10.24432/C5T01Q](https://doi.org/10.24432/C5T01Q).\n",
    "\n",
    "---\n",
    "\n",
    "## Annexe\n",
    "\n",
    "### Bibliothèque *Seaborn*\n",
    "\n",
    "[*Seaborn*](https://seaborn.pydata.org) est une bibliothèque de visualisation en\n",
    "Python qui vient en surcouche de *Matplotlib*. Elle permet de créer facilement des\n",
    "graphiques statistiques multivariables. Par exemple :\n",
    "\n",
    "- des distribution de données avec les fonctions `sns.histplot()`, `sns.kdeplot()` ;\n",
    "- des nuages de points : `sns.scatterplot()` ;\n",
    "- des boîtes à moustaches : `sns.boxplot()`.\n",
    "\n",
    "#### Exemple\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assurez-vous que le DataFrame 'df' est déjà chargé avec les données de 'sonar.csv'\n",
    "# et que les colonnes sont correctement nommées comme dans les exercices précédents.\n",
    "\n",
    "# Histogramme de la distribution de la caractéristique 1\n",
    "sns.histplot(df['Attribute1'], kde=True)\n",
    "plt.title('Distribution de la caractéristique 1')\n",
    "plt.xlabel('Valeurs de Attribute1')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()\n",
    "\n",
    "# Nuage de points des caractéristiques 1 et 2\n",
    "sns.scatterplot(data=df, x='f1', y='f2', hue='class')\n",
    "plt.title('Nuage de points des caractéristiques 1 et 2')\n",
    "plt.xlabel('Attribute1')\n",
    "plt.ylabel('Attribute2')\n",
    "plt.legend(title='Classe')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot pour comparer la caractéristique 1 selon la cible\n",
    "sns.boxplot(data=df, x='class', y='f1')\n",
    "plt.title('Boxplot de la caractéristique 1 selon la cible')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Valeurs de Attribute1')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
