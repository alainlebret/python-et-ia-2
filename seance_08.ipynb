{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: solid;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\n",
    "  border-radius: 10px;\">\n",
    "\n",
    "# **Python et intelligence artificielle**\n",
    "\n",
    "# *Séance n°8 : Optimisation et descente de gradient*\n",
    "\n",
    "</div>\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Lors de la séance précédente, vous avez mis en oeuvre une régression linéaire à l'aide de la classe `LinearRegression` de *Scikit-learn* en entraînant le modèle à l'aide de sa méthode `fit()`. Aujourd'hui, nous allons explorer en détail le mécanisme sous-jacent : comment les paramètres d'un modèle de régression linéaire sont-ils ajustés pour minimiser l'erreur de prédiction ?\n",
    "\n",
    "L'objectif de cette séance est d'introduire et de mettre en pratique la **descente de gradient**, une méthode d'optimisation fondamentale en apprentissage automatique. Vous allez notamment :\n",
    "\n",
    "- Comprendre la notion de **fonction de coût** dans le cadre de la régression linéaire.\n",
    "- Implémenter l'algorithme de **descente de gradient** afin de minimiser cette fonction.\n",
    "- Comparer trois variantes de l'algorithme : **par lot**, **stochastique** et par **mini-lots**.\n",
    "- Observer l'effet de la **standardisation des données** sur la convergence de la descente de gradient.\n",
    "- Appliquer la descente de gradient à un problème d'estimation de résistances.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Régression linéaire\n",
    "\n",
    "On rappelle qu'une régression linéaire simple cherche à modéliser la relation entre une variable cible $y$ et une variable explicative $X$. Cette relation est exprimée sous la forme d'une droite :\n",
    "\n",
    "$$\n",
    "y = \\theta_1 X + \\theta_0\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $\\theta_0$ est l'ordonnée à l'origine, soit la valeur de $y$ lorsque $X = 0$.\n",
    "- $\\theta_1$ représente la pente de la droite et indique la variation de $y$ pour chaque unité d'augmentation de $X$.\n",
    "\n",
    "### Fonction de coût\n",
    "\n",
    "En apprentissage automatique, on cherche à minimiser l'erreur entre les prédictions du modèle et les valeurs réelles. Cette erreur est mesurée par une fonction de coût. Pour la régression linéaire, la fonction de coût la plus courante est l'erreur quadratique moyenne :\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $m$ est le nombre d'exemples dans le jeu de données ;\n",
    "- $h_{\\theta}(x^{(i)})$ est la prédiction pour l'exemple $i$ avec les paramètres $\\theta$ ;\n",
    "- $y^{(i)}$ est la valeur réelle pour l'exemple $i$.\n",
    "\n",
    "L'objectif est de minimiser cette fonction en trouvant les paramètres $\\theta_0$ et $\\theta_1$.\n",
    "\n",
    "#### Nécessité d'une colonne de biais pour $X$\n",
    "\n",
    "La fonction de prédiction est la suivante :\n",
    "\n",
    "$$\n",
    "h_{\\theta}(X) = X \\cdot \\theta\n",
    "$$\n",
    "\n",
    "Si $X$ est une matrice sans colonne de biais, elle contiendra uniquement les valeurs de la variable explicative (ex : température, taille, etc.). Cependant, pour inclure $\\theta_0$, nous devons ajouter à chaque ligne de $X$ une première colonne remplie de 1 de manière à tenir compte du décalage constant à chaque prédiction.\n",
    "\n",
    "En Python, on utilise souvent `np.c_` pour concaténer une colonne de 1 à $X$ de la manière suivante :\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3]])\n",
    "X_biais = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "print(X_biais)\n",
    "```\n",
    "</div>\n",
    "\n",
    "Une autre solution consiste à faire appel à la fonction `hstack()` de *Numpy* :\n",
    "\n",
    "<div style=\"\n",
    "  padding: 5pt;\n",
    "  border-style: dashed;\n",
    "  border-width: 1px;\n",
    "  border-color: gray;\">\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "m = len(y)\n",
    "# Ajout d'une colonne de 1 à X pour le biais\n",
    "X_biais = np.hstack((np.ones((m, 1)), X))\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "### Descente de gradient\n",
    "\n",
    "La descente de gradient est une méthode pour ajuster les paramètres $\\theta$ afin de minimiser la fonction de coût. Elle consiste à calculer, pour chaque paramètre, dans quelle direction ajuster sa valeur de manière à réduire la fonction de coût. À chaque itération, l'algorithme ajuste les paramètres dans cette direction en suivant la règle :\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\alpha \\nabla_{\\theta} J(\\theta)\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $\\alpha$ est le taux d'apprentissage (*learning rate*) qui contrôle l'amplitude des ajustements. S'il est trop élevé, l'algorithme risque de diverger. S'il est trop faible, sa convergence sera lente.\n",
    "- $\\nabla_{\\theta} J(\\theta)$ est le gradient de la fonction de coût par rapport aux paramètres $\\theta$.\n",
    "\n",
    "Le gradient, en somme, est un vecteur qui pointe dans la direction de la plus forte augmentation de la fonction de coût. En prenant la direction opposée, on réduit la valeur de la fonction de coût.\n",
    "Imaginez que vous descendiez une colline à l'aveugle. À chaque étape, vous ajustez votre trajectoire pour descendre dans la direction la plus raide que vous ressentez. C'est ce que fait la descente de gradient : elle \"descend\" le long de la fonction de coût afin de trouver son minimum.\n",
    "\n",
    "### Calcul du gradient dans le cas de la régression linéaire\n",
    "\n",
    "Dans le cas d'une régression linéaire, la fonction de coût a une forme quadratique, ce qui simplifie le calcul du gradient. Le gradient est donné par :\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} J(\\theta) = \\frac{1}{m} X^T (X \\theta - y)\n",
    "$$\n",
    "\n",
    "Nous utiliserons cette formule pour ajuster les paramètres $\\theta$ à chaque itération et ainsi minimiser la fonction de coût.\n",
    "\n",
    "### Variantes de la descente de gradient\n",
    "\n",
    "Il existe plusieurs variantes de la descente de gradient, chacune ayant des propriétés spécifiques qui influencent le temps de convergence et la précision. En voici trois :\n",
    "\n",
    "1. La **descente par lot** (*batch gradient descent*) qui utilise l'ensemble des données pour calculer le gradient à chaque itération. Ell converge de manière stable vers le minimum global (surtout pour les fonctions convexes comme ici), par contre l'algorithme est long à exécuter sur de très grands jeux de données, car chaque itération nécessite l'ensemble des exemples.\n",
    "2. La **descente stochastique** (*stochastic gradient descent*) qui utilise un seul exemple aléatoire à chaque mise à jour des paramètres. Elle converge rapidement, même pour de grands ensembles de données, mais le chemin de convergence peut être irrégulier et oscillant autour du minimum.\n",
    "3. La **descente par mini-lots** (*mini-batch gradient descent*) qui divise le jeu de données en mini-lots d'exemples pour calculer les mises à jour. C'est un compromis entre la vitesse de la descente stochastique et la stabilité de la descente par lot. Par contre, elle nécessite de bien choisir la taille des mini-lots pour un compromis optimal.\n",
    "\n",
    "Pour un jeu de données contenant des milliers de points, la descente stochastique peut converger plus rapidement que la descente par lot complet, mais au prix d'une précision réduite. Par ailleurs, les mini-lots permettent d'obtenir une convergence stable avec un compromis acceptable entre vitesse et précision.\n",
    "\n",
    "Remarque : les variables dans les jeux de données peuvent avoir des échelles différentes (par exemple, température en °C et pression en hPa). La standardisation (centrage autour de 0 et réduction à un écart-type de 1) peut améliorer la vitesse de convergence en ajustant toutes les variables à la même échelle.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercice 1 : implémentation de la fonction de coût\n",
    "\n",
    "Avant d'implémenter la descente de gradient, nous devons d'abord écrire la fonction de coût, qui est un critère de performance du modèle. La fonction de coût à utiliser est l'erreur quadratique moyenne (ou MSE).\n",
    "\n",
    "1. Écrivez la fonction `calculer_cout(X, y, theta)` qui retourne l'erreur quadratique moyenne dans le cas d'une régression linéaire. Les paramètres de la fonction sont :\n",
    "   - `X` : une matrice représentant les valeurs de la variable explicative.\n",
    "   - `y` : un vecteur des valeurs cibles.\n",
    "   - `theta` : un vecteur des paramètres du modèle $(\\theta_0, \\theta_1)$.\n",
    "2. Testez la fonction avec les valeurs suivantes et vérifiez qu'elle vous retourne environ 2,33.\n",
    "\n",
    "   <div style=\"\n",
    "      padding: 5pt;\n",
    "      border-style: dashed;\n",
    "      border-width: 1px;\n",
    "      border-color: gray;\">\n",
    "\n",
    "   ```python\n",
    "   X = np.array([[1], [2], [3]])\n",
    "   y = np.array([[2], [4], [6]])\n",
    "   theta = np.array([[0], [1]])\n",
    "   ```\n",
    "\n",
    "   </div>\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 2 : Implémentation de la descente de gradient\n",
    "\n",
    "1. Écrivez la fonction `descente_gradient(X, y, theta, alpha, n_iterations)` permettant de minimiser la fonction de coût et d'ajuster les paramètres du modèle. Les paramètres de la fonction sont :\n",
    "\n",
    "   - `X` : une matrice représentant les valeurs de la variable explicative **et sa colonne de biais**.\n",
    "   - `y` : un vecteur des valeurs cibles.\n",
    "   - `theta` : un vecteur des paramètres du modèle $(\\theta_0, \\theta_1)$.\n",
    "   - `alpha` : le taux d'apprentissage.\n",
    "   - `n_iterations` : le nombre d'itérations de l'algorithme.\n",
    "\n",
    "   La fonction retourne `theta` ainsi qu'une liste de l'historique des coûts.\n",
    "2. Tracez l'évolution du coût\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 3 : Expérience de mesure de résistance\n",
    "\n",
    "Dans cet exercice, vous allez appliquer l'algorithme de descente de gradient pour modéliser la résistance $R$ d'un matériau en fonction de la température $T$. On considère une relation linéaire entre $R$ et $T$ de la forme :\n",
    "\n",
    "$$\n",
    "R = \\theta_0 + \\theta_1 T\n",
    "$$\n",
    "\n",
    "1. Utilisez le code ci-dessous pour générer un ensemble de données de température et de résistance simulées avec un bruit aléatoire.\n",
    "   \n",
    "   <div style=\"\n",
    "      padding: 5pt;\n",
    "      border-style: dashed;\n",
    "      border-width: 1px;\n",
    "      border-color: gray;\">\n",
    "\n",
    "   ```python\n",
    "   import numpy as np\n",
    "   import matplotlib.pyplot as plt\n",
    "\n",
    "   # Paramètres réels\n",
    "   R0_true = 10  # Ohms\n",
    "   alpha_true = 0.004  # 1/°C\n",
    "\n",
    "   # Génération des températures et résistances\n",
    "   T = np.linspace(0, 100, 50).reshape(-1, 1)\n",
    "   noise = np.random.normal(0, 0.5, T.shape)\n",
    "   R = R0_true * (1 + alpha_true * T) + noise\n",
    "\n",
    "   plt.scatter(T, R)\n",
    "   plt.xlabel('Température (°C)')\n",
    "   plt.ylabel('Résistance (Ohms)')\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "   </div>\n",
    "\n",
    "2. Standardisez les données pour que les différences d'échelle ne ralentisse pas la convergence.\n",
    "3. Utilisez la fonction de descente de gradient que vous avez implémentée pour estimer les valeurs de $\\theta_0$ et $\\theta_1$.\n",
    "4. Affichez la courbe de convergence de la fonction de coût.\n",
    "5. Comparez les paramètres estimés avec les valeurs réelles.\n",
    "6. Tracez les prédictions du modèle sur les données et commentez la qualité de l'ajustement.\n",
    "\n",
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercice 4 : Impact de la standardisation et comparaison des méthodes\n",
    "\n",
    "Dans cet exercice, vous allez explorer comment la standardisation et les variantes de la descente de gradient influencent la convergence.\n",
    "\n",
    "1. Répétez l'exercice précédent sans standardiser les données et observez les différences dans la convergence.\n",
    "2. Commentez les effets observés.\n",
    "3. Reprenez l'implémentation de `descente_gradient()` et adaptez-la pour chaque méthode.\n",
    "4. Pour chaque méthode, visualisez la convergence et comparez le nombre d'itérations nécessaires pour atteindre une bonne précision.\n",
    "5. Expliquez comment chaque méthode influence la précision et la vitesse de convergence.\n",
    "6. Indiquez dans quels contextes chaque méthode serait à privilégier.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Dans cette séance vous avez :\n",
    "\n",
    "- mis en pratique la descente de gradient dans le cas d'un modèle de régression linéaire ;\n",
    "- comparé l'impact de la standardisation sur la convergence ;\n",
    "- observé comment chaque variante de descente de gradient affecte la vitesse et la précision de l'algorithme.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
